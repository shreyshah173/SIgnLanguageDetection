{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b858d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56dda1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fbddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False  # Image is no longer writeable\n",
    "    results = model.process(image)  # Make prediction\n",
    "    image.flags.writeable = True  # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b29908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # face pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                               )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                               )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cd79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "569f080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.5296849\n",
       "y: 0.5940437\n",
       "z: -0.91820306\n",
       "visibility: 0.9998221"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks.landmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0c6601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.5296849 ,  0.59404367, -0.91820306,  0.99982208]),\n",
       " array([ 0.55173963,  0.52071422, -0.84448874,  0.99967629]),\n",
       " array([ 0.56490618,  0.52227306, -0.84436959,  0.99953926]),\n",
       " array([ 0.57710207,  0.52389568, -0.84457147,  0.99955493]),\n",
       " array([ 0.50219715,  0.5118776 , -0.86590689,  0.99976343]),\n",
       " array([ 0.48007184,  0.50669849, -0.86525214,  0.99975604]),\n",
       " array([ 0.45541731,  0.50248092, -0.8654806 ,  0.99983108]),\n",
       " array([ 0.58040857,  0.54556209, -0.35841358,  0.99934316]),\n",
       " array([ 0.39381614,  0.52207756, -0.44760242,  0.99985063]),\n",
       " array([ 0.5370847 ,  0.66451257, -0.75371784,  0.99975294]),\n",
       " array([ 0.48028454,  0.66129196, -0.77322763,  0.9998492 ]),\n",
       " array([ 0.67594045,  0.89894873, -0.07935663,  0.99670881]),\n",
       " array([ 0.23652521,  0.89221072, -0.3961502 ,  0.99927384]),\n",
       " array([0.72611129, 1.38412774, 0.14888044, 0.11164055]),\n",
       " array([-0.03315427,  1.23604417, -1.18417108,  0.97544879]),\n",
       " array([0.74240541, 1.74839616, 0.19758877, 0.09721   ]),\n",
       " array([ 0.154862  ,  0.71992344, -2.06170797,  0.97710717]),\n",
       " array([0.77708298, 1.86401808, 0.19270036, 0.11692782]),\n",
       " array([ 0.20868631,  0.55912513, -2.25687218,  0.93488896]),\n",
       " array([0.7384522 , 1.85956156, 0.15465179, 0.16209096]),\n",
       " array([ 0.2384135 ,  0.54789859, -2.15454412,  0.94261801]),\n",
       " array([0.70759821, 1.82449341, 0.16897626, 0.17353758]),\n",
       " array([ 0.23866284,  0.59116215, -2.04619551,  0.93587148]),\n",
       " array([ 5.85812390e-01,  1.75663197e+00, -4.77177911e-02,  1.52614317e-03]),\n",
       " array([0.25854641, 1.75712705, 0.05212504, 0.00200663]),\n",
       " array([ 5.66655159e-01,  2.48311114e+00, -2.19144732e-01,  6.95484865e-04]),\n",
       " array([2.86502540e-01, 2.49752426e+00, 2.19071247e-02, 5.38507767e-04]),\n",
       " array([5.45005918e-01, 3.15262651e+00, 3.49603862e-01, 9.36480283e-05]),\n",
       " array([2.78455913e-01, 3.14516950e+00, 4.81182516e-01, 1.17000382e-05]),\n",
       " array([5.44534087e-01, 3.24165511e+00, 3.62380594e-01, 4.24319842e-05]),\n",
       " array([2.64316112e-01, 3.23038435e+00, 5.17820954e-01, 2.47319567e-05]),\n",
       " array([ 5.10295033e-01,  3.35529470e+00, -3.08505982e-01,  3.68162291e-05]),\n",
       " array([ 3.13230306e-01,  3.35355163e+00, -2.36980945e-01,  4.84615157e-05])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x , res.y , res.z , res.visibility])\n",
    "    pose.append(test)\n",
    "\n",
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d058a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51880121,  0.67780244, -0.01375741],\n",
       "       [ 0.53037387,  0.64541072, -0.04697132],\n",
       "       [ 0.5217852 ,  0.65190393, -0.02020814],\n",
       "       ...,\n",
       "       [ 0.53619921,  0.55586493, -0.01318693],\n",
       "       [ 0.5799129 ,  0.54235178,  0.01809301],\n",
       "       [ 0.58447057,  0.53678483,  0.01946235]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose = np.array([[res.x , res.y ,res.z , res.visibility] for res in results.pose_landmarks.landmark])\n",
    "lh = np.array([[res.x , res.y , res.z] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x , res.y , res.z] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros(21*3)\n",
    "face = np.array([[res.x , res.y ,res.z] for res in results.face_landmarks.landmark]) if results.face_landmarks else np.zeros(468*3)\n",
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3b44a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh\n",
    "# shape will give the idea of everything for the project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d13f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51803687e-01,  7.41745710e-01,  4.50651413e-07],\n",
       "       [ 2.20287144e-01,  7.24534452e-01, -2.14877818e-02],\n",
       "       [ 2.85042465e-01,  6.83744311e-01, -3.37836221e-02],\n",
       "       [ 3.33688796e-01,  6.45053387e-01, -4.63540964e-02],\n",
       "       [ 3.75485063e-01,  6.06126308e-01, -5.84954657e-02],\n",
       "       [ 2.75136590e-01,  5.36274076e-01, -9.82520729e-03],\n",
       "       [ 3.14647913e-01,  4.57955837e-01, -2.89792754e-02],\n",
       "       [ 3.40469182e-01,  4.13238823e-01, -4.69264425e-02],\n",
       "       [ 3.65516931e-01,  3.74540150e-01, -5.99683896e-02],\n",
       "       [ 2.45385647e-01,  5.15190721e-01, -1.54435029e-02],\n",
       "       [ 2.79145390e-01,  4.23771501e-01, -3.04265562e-02],\n",
       "       [ 3.05764854e-01,  3.68153512e-01, -4.60115261e-02],\n",
       "       [ 3.30089360e-01,  3.23332489e-01, -5.81819043e-02],\n",
       "       [ 2.12145582e-01,  5.14382541e-01, -2.52723973e-02],\n",
       "       [ 2.42722318e-01,  4.28139776e-01, -4.08256426e-02],\n",
       "       [ 2.70874202e-01,  3.80992264e-01, -5.13063110e-02],\n",
       "       [ 2.98521906e-01,  3.40873867e-01, -5.92714734e-02],\n",
       "       [ 1.74306959e-01,  5.30725002e-01, -3.78421284e-02],\n",
       "       [ 1.91366360e-01,  4.65986520e-01, -5.30509651e-02],\n",
       "       [ 2.12135658e-01,  4.25948501e-01, -5.85931353e-02],\n",
       "       [ 2.34430179e-01,  3.88670325e-01, -6.20922223e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db964c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    keypoints = []\n",
    "    \n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark])\n",
    "    if pose.shape[0] != 0:\n",
    "        keypoints.append(pose)\n",
    "    \n",
    "    lh = np.array([[res.x, res.y, res.z, 0] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros((0, 4))\n",
    "    if lh.shape[0] != 0:\n",
    "        keypoints.append(lh)\n",
    "    \n",
    "    rh = np.array([[res.x, res.y, res.z, 0] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros((0, 4))\n",
    "    if rh.shape[0] != 0:\n",
    "        keypoints.append(rh)\n",
    "    \n",
    "    face = np.array([[res.x, res.y, res.z, 0] for res in results.face_landmarks.landmark]) if results.face_landmarks else np.zeros((0, 4))\n",
    "    if face.shape[0] != 0:\n",
    "        keypoints.append(face)\n",
    "    \n",
    "    if keypoints:\n",
    "        keypoints = np.concatenate(keypoints, axis=0)\n",
    "    else:\n",
    "        keypoints = np.zeros((0, 4))  # Use (0, 4) to match the shape of the pose array\n",
    "    \n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4564edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['hello', 'thanks', 'iloveyou'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "# hello\n",
    "## 0\n",
    "## 1\n",
    "## 2\n",
    "## ...\n",
    "## 29\n",
    "# thanks\n",
    "\n",
    "# I love you\n",
    "for action in actions: \n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f34a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currentjiol p;'directory: C:\\Users\\admin\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"Currentjiol p;'directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ec1b2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # NEW LOOP\n",
    "    # Loop through actions\n",
    "    for action in actions:\n",
    "        # Loop through sequences aka videos\n",
    "        for sequence in range(no_sequences):\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "#                 print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                # NEW Apply wait logic\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(2000)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8919dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee283ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
